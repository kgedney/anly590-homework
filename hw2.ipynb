{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    " \n",
    "### ANLY 590 | Homework 2\n",
    "### Kendra Gedney | kg729@georgetown.edu \n",
    "\n",
    "<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "import os\n",
    "path = '/Users/kgedney/Documents/georgetown/anly590/anly590-homework'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_For this problem, I used the same network as in the blo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A convolutional autoencoder is a particular flavor of autoencoder where we use convolutional layers instead of dense layers. We have previously applied autoencoders to images using only Dense layers and the result worked fairly well. However, the local spatial correlations of images imply that we should be able to do better using convolutional layers instead of Dense layers.   \n",
    "   \n",
    "Build and fit a convolutional autoencoder for the Fashion MNIST dataset. The components of this network will be many of the same pieces we’ve used with convolutional classification networks: Conv2D, MaxPooling, and so on. The encoder part of the network should run the input image through a few convolutional layers of your choice. The decoder part of the network will utilize UpSampling2D to get the representation back to the original image size.   \n",
    "\n",
    "An example to guide your thinking can be found toward the bottom of this post https://blog.keras.io/building-autoencoders-in-keras.html.\n",
    "   \n",
    "After training your network, visualize some examples of input images and their decoded reconstruction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# check shapes\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# normalize grayscale\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test.astype('float32') / 255.\n",
    "\n",
    "# reshape images\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test  = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_test  = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10 classes of clothing types - make categorical\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kgedney/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# copy network from blog post\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 50s 831us/step - loss: 0.3596 - val_loss: 0.3420\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.3273 - val_loss: 0.3249\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 56s 933us/step - loss: 0.3166 - val_loss: 0.3148\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 58s 965us/step - loss: 0.3105 - val_loss: 0.3109\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 57s 949us/step - loss: 0.3069 - val_loss: 0.3072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x142cb6d68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train network\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAD4CAYAAAB7VPbbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x142d7f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize images before and after decoding\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "n=10\n",
    "for k in range(n):\n",
    "    ax = plt.subplot(2, n, k+1)\n",
    "    plt.imshow(x_test[k:k+1,:].reshape((28,28)), \"gray\")\n",
    "    ax = plt.subplot(2, n, k+1 + n)\n",
    "    reconstruction = autoencoder.predict(x_test[k:k+1,:])\n",
    "    reconstruction.resize((28,28))\n",
    "    plt.imshow(reconstruction, \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.1: Deep CNN\n",
    "Build a deep CNN to classify the images. Provide a brief description of the architectural choices you’ve made: kernel sizes, strides, padding, network depth. Train your network end-to-end. Report on your model’s performance on training set and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first used the LeNet architecture -> 86% test accuracy\n",
    "- did a more simple model, but with less dropout, and larger denser layer at the end -> \n",
    "- found that adam optimizer resulted in some modest accuracy gains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use same dataset as before so inputs are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kgedney/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# start with a LeNet arichtecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid', input_shape=(28,28,1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kgedney/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2857: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.5467 - acc: 0.7956 - val_loss: 0.4759 - val_acc: 0.8236\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 0.4816 - acc: 0.8230 - val_loss: 0.4469 - val_acc: 0.8324\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.4417 - acc: 0.8377 - val_loss: 0.3864 - val_acc: 0.8624\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 25s 413us/step - loss: 0.4136 - acc: 0.8494 - val_loss: 0.3752 - val_acc: 0.8618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143f314e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=4, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 102us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37518016321659087, 0.8618]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 86% test accuracy\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more simple \n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(filters = 32, kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid', input_shape=(28,28,1)))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128))\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.4580 - acc: 0.8390 - val_loss: 0.3707 - val_acc: 0.8693\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 0.3313 - acc: 0.8839 - val_loss: 0.3389 - val_acc: 0.8808\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.3012 - acc: 0.8943 - val_loss: 0.3120 - val_acc: 0.8886\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.2832 - acc: 0.8998 - val_loss: 0.2992 - val_acc: 0.8954\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 25s 418us/step - loss: 0.2707 - acc: 0.9041 - val_loss: 0.2873 - val_acc: 0.8969\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 0.2595 - acc: 0.9092 - val_loss: 0.2865 - val_acc: 0.8994\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 0.2525 - acc: 0.9108 - val_loss: 0.2771 - val_acc: 0.9012\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.2461 - acc: 0.9111 - val_loss: 0.2806 - val_acc: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143fc1c50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=8, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 101us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28056134787797926, 0.8989]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model2 has 89.89% accuracy\n",
    "model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test model3 -> padding='same' but the images dont seem to go right to edge anyways.. \n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(filters = 32, kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='same', input_shape=(28,28,1)))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128))\n",
    "model3.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.4489 - acc: 0.8430 - val_loss: 0.3578 - val_acc: 0.8690\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 29s 491us/step - loss: 0.3254 - acc: 0.8850 - val_loss: 0.3194 - val_acc: 0.8863\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.2947 - acc: 0.8965 - val_loss: 0.3078 - val_acc: 0.8912\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.2765 - acc: 0.9017 - val_loss: 0.3067 - val_acc: 0.8896\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.2648 - acc: 0.9060 - val_loss: 0.2981 - val_acc: 0.8924\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 29s 478us/step - loss: 0.2532 - acc: 0.9090 - val_loss: 0.2873 - val_acc: 0.8948\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 30s 500us/step - loss: 0.2471 - acc: 0.9134 - val_loss: 0.2874 - val_acc: 0.8954\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 30s 494us/step - loss: 0.2406 - acc: 0.9153 - val_loss: 0.2760 - val_acc: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143143a90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train, y_train, epochs=8, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 111us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27598051676750185, 0.9032]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test model4 -> padding='valid' but change the kernel size\n",
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Conv2D(filters = 32, kernel_size=(5,5), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='same', input_shape=(28,28,1)))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128))\n",
    "model4.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.3911 - acc: 0.8610 - val_loss: 0.3355 - val_acc: 0.8821\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 32s 541us/step - loss: 0.2939 - acc: 0.8936 - val_loss: 0.3154 - val_acc: 0.8900\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 36s 605us/step - loss: 0.2651 - acc: 0.9039 - val_loss: 0.3252 - val_acc: 0.8857\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.2448 - acc: 0.9107 - val_loss: 0.2898 - val_acc: 0.8968\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 35s 586us/step - loss: 0.2335 - acc: 0.9143 - val_loss: 0.2836 - val_acc: 0.9000\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.2234 - acc: 0.9173 - val_loss: 0.2795 - val_acc: 0.9052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143143080>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train, y_train, epochs=6, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 164us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27819047354459764, 0.9003]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adadelta\n",
    "model4.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 149us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27947091865539553, 0.9052]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adam\n",
    "model4.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sgd - worse!\n",
    "model4.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 28s 470us/step - loss: 0.6633 - acc: 0.7664 - val_loss: 0.5071 - val_acc: 0.8199\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 30s 503us/step - loss: 0.4569 - acc: 0.8384 - val_loss: 0.4428 - val_acc: 0.8407\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 31s 518us/step - loss: 0.4080 - acc: 0.8576 - val_loss: 0.4061 - val_acc: 0.8555\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.3798 - acc: 0.8667 - val_loss: 0.3888 - val_acc: 0.8607\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 30s 497us/step - loss: 0.3588 - acc: 0.8744 - val_loss: 0.3633 - val_acc: 0.8716\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.3427 - acc: 0.8797 - val_loss: 0.3426 - val_acc: 0.8807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a0bc550>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.2:  Transfer Learning\n",
    "Repeat the same task, but this time utilize a pre-trained network for the majority of your model. You should only train the final Dense layer, all other weights should be fixed. You can use whichever pre-trained backbone you like (ResNet, VGG, etc). Report on your model’s performance on training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ref: https://medium.com/@sidereal/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "import cv2\n",
    "x_train_big = np.asarray([cv2.resize(x, (48,48)) for x in x_train])\n",
    "x_test_big  = np.asarray([cv2.resize(x, (48,48)) for x in x_test])\n",
    "# plt.imshow(x_train_big[9], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape \n",
    "x_train_big = x_train_big.reshape(x_train_big.shape[0], 48, 48,1)\n",
    "x_test_big  = x_test_big.reshape(x_test_big.shape[0], 48, 48, 1)\n",
    "\n",
    "# make gray images into rgb images\n",
    "x_train_big = x_train_big.repeat(3, axis=-1)\n",
    "x_test_big  = x_test_big.repeat(3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep VGG backbone\n",
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 14,848,586\n",
      "Trainable params: 133,898\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# freeze weights so that we only train the final layers\n",
    "conv_base.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "35296/60000 [================>.............] - ETA: 6:56 - loss: 0.5276 - acc: 0.8115"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d49959a0652e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(x_test_big, y_test))\n\u001b[0m",
      "\u001b[0;32m/Users/kgedney/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/kgedney/anaconda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kgedney/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kgedney/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kgedney/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train_big, \n",
    "          y_train,\n",
    "          epochs=5, \n",
    "          validation_data=(x_test_big, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While images contain local spatial correlations and structure, many other datasets contain temporal correlations. Examples include time series and discrete se- quences such as text. In this problem, we will tackle the task of text classification in the context of cybersecurity.\n",
    "\n",
    "**Background:**   \n",
    "When malware infects a host computer, it often needs to reach out to an outside server for further instructions or to download additional payloads. This outside server is called a Command-and-Control server (C2). The malware needs to send a specific communication to the C2 server, thus the C2 server needs to have a registered IP address or associated web domain so that it can be reached. Therefore, being able to identify web domains that are likely related to malware C2 can be a valuable cyber defense.\n",
    "\n",
    "**Dataset:**    \n",
    "\n",
    "Fortunately, security researchers have already identified and logged a large number of malicious URLs. Additionally, we can catalog common ”be- nign” URLs just from typical web behavior (these would include things like facebook.com and amazon.com). Hence, we have a labeled dataset for text classification which can be downloaded here:\n",
    "-  https://s3.amazonaws.com/anly-590/url-classification/benign-urls.txt\n",
    "- https://s3.amazonaws.com/anly-590/url-classification/malicious-urls.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1: RNN\n",
    "Build and train a Recurrent Neural Network to solve this text classification task. You can use any type of RNN you wish (SimpleRNN, GRU, LSTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2: CNN\n",
    "Build and train a 1D CNN for this text classification task. You might gain some insight and inspiration from these text classification approaches:\n",
    "-  http://www.aclweb.org/anthology/D14-1181 \n",
    "-  https://arxiv.org/abs/1702.08568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
